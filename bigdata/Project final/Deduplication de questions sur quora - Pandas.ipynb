{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude \n",
    "\n",
    "Ce notebook a pour objectif de tester les perfomances de pandas sur un dataset de questions posées sur quora. \n",
    "Le but est de dédupliquer les questions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177827.94100389228"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**5.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données\n",
    "\n",
    "Pour tester les perfomances de pandas à la lecture de données nous allons simplement charger le dataframe en memoire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 139 ms, total: 1.15 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_full = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    1000: df_full[:1000].copy(),\n",
    "    10000: df_full[:10000].copy(),\n",
    "    100000: df_full[:100000].copy(),\n",
    "    400000: df_full,\n",
    "    800000: df_full.append(df_full),\n",
    "    1200000: df_full.append(df_full).append(df_full)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Séparation des données en un ensemble d'apprentissage et un ensemble de validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "taux_sep = 0.7\n",
    "def split_dataset(df, taux_sep):\n",
    "    return train_test_split(df, train_size=taux_sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nettoyage des données\n",
    "\n",
    "Pour le nettoyage des données nous allons:\n",
    "- supprimer les questions vides\n",
    "- retirer les stopwords\n",
    "- passer le text en minuscule\n",
    "- tokenizer les questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "english_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_string(string: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove stopwords and stem the string\n",
    "    \"\"\"\n",
    "    if isinstance(string, str):\n",
    "        string = string.lower()\n",
    "        words = []\n",
    "        for word in string.split():\n",
    "            if word not in english_stopwords:\n",
    "                words.append(word)\n",
    "        return words\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    # Questions en minuscule\n",
    "    for column in ['question1', 'question2']:\n",
    "        df[column] = df[column].apply(clean_string)\n",
    "    # Suppression des NaN\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_time = {}\n",
    "df_cleaned = {}\n",
    "for key, df in df_dict.items():\n",
    "    st = time.time()\n",
    "    df_cleaned[key] = clean_dataframe(df)\n",
    "    cleaning_time[key] = time.time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{400000: 3.833127975463867,\n",
       " 1000: 0.01153707504272461,\n",
       " 10000: 0.08499813079833984,\n",
       " 100000: 1.0665977001190186,\n",
       " 800000: 8.105329990386963,\n",
       " 1200000: 11.493905782699585}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Représentation des données.\n",
    "\n",
    "Pour la representation des données nous avons:\n",
    "- Compter le nombre de mots communs entre les questions\n",
    "- Compter le nombre de mots communs entre les questions pondérés par l'idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(count, eps=10000, min_count=2):\n",
    "    if count < min_count:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 / (count + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(df):\n",
    "    questions = df[['qid1','question1']].rename(columns={'qid1': 'qid','question1':'question'})\\\n",
    "    .append(df[['qid2','question2']].rename(columns={'qid2': 'qid','question2':'question'})).drop_duplicates('qid')\\\n",
    "    .question.values\n",
    "\n",
    "    counts = defaultdict(lambda : 0)\n",
    "\n",
    "    for question in questions:\n",
    "        if question:\n",
    "            for word in question:\n",
    "                counts[word] += 1\n",
    "\n",
    "    idf = {word: get_weight(count) for word, count in counts.items()}\n",
    "\n",
    "    return idf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_time = {}\n",
    "idf_dict = {}\n",
    "for key, df in df_dict.items():\n",
    "    st = time.time()\n",
    "    idf_dict[key] = compute_idf(df)\n",
    "    idf_time[key] = time.time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1000: 0.015150070190429688,\n",
       " 10000: 0.04743003845214844,\n",
       " 100000: 0.3630099296569824,\n",
       " 400000: 1.2766520977020264,\n",
       " 800000: 1.420454740524292,\n",
       " 1200000: 1.794395923614502}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def common_words(df):\n",
    "    def common_words(row):\n",
    "        question1 = row['question1']\n",
    "        question2 = row['question2']\n",
    "        common_words = 0\n",
    "        number_of_words = len(question1) + len(question2)\n",
    "        for word in question1:\n",
    "            if word in question2:\n",
    "                common_words += 1\n",
    "        return 2 * common_words / number_of_words\n",
    "    df['common_words'] = df.apply(common_words, axis='columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "df_common_words = {}\n",
    "common_words_time = {}\n",
    "for key, df in df_cleaned.items():\n",
    "    st = time.time()\n",
    "    df_common_words[key] = common_words(df)\n",
    "    common_words_time[key] = time.time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{400000: 15.429856061935425,\n",
       " 1000: 0.035256147384643555,\n",
       " 10000: 0.351970911026001,\n",
       " 100000: 3.493546962738037,\n",
       " 800000: 30.880029916763306,\n",
       " 1200000: 50.30730128288269}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_words_idf_weighted(df, idf):\n",
    "    def common_words_idf_weighted(row):\n",
    "        question1 = row['question1']\n",
    "        question2 = row['question2']\n",
    "        common_words_weighted = 0\n",
    "        questions_weights = 0\n",
    "        for word in question1:\n",
    "            idf_weight = idf[word]\n",
    "            if word in question2:\n",
    "                common_words_weighted += idf_weight\n",
    "            questions_weights += idf_weight\n",
    "        for word in question2:\n",
    "            questions_weights += idf[word]\n",
    "        if questions_weights > 0:\n",
    "            return 2 * common_words_weighted / questions_weights\n",
    "        else:\n",
    "            return 0\n",
    "    df['common_words_idf_weighted'] = df.apply(common_words_idf_weighted, axis='columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_common_words_idf = {}\n",
    "common_words_idf_time = {}\n",
    "for key, df in df_common_words.items():\n",
    "    idf = idf_dict[key]\n",
    "    st = time.time()\n",
    "    df_common_words_idf[key] = common_words_idf_weighted(df, idf)\n",
    "    common_words_idf_time[key] = time.time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{400000: 25.642945051193237,\n",
       " 1000: 0.052175045013427734,\n",
       " 10000: 0.43926310539245605,\n",
       " 100000: 3.947237014770508,\n",
       " 800000: 32.78772020339966,\n",
       " 1200000: 49.21293520927429}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_idf_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Processing pour les models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_dict = {}\n",
    "test_dict = {}\n",
    "x_train_dict = {}\n",
    "x_test_dict = {}\n",
    "y_train_dict = {}\n",
    "y_test_dict = {}\n",
    "\n",
    "selected_columns = ['common_words', 'common_words_idf_weighted']\n",
    "\n",
    "for key, df in df_common_words_idf.items():\n",
    "    train, test = split_dataset(df, taux_sep)\n",
    "    train_dict[key] = train.dropna()\n",
    "    test_dict[key] = test.dropna()\n",
    "\n",
    "    x_train_dict[key] = train_dict[key][selected_columns]\n",
    "\n",
    "    x_test_dict[key] = test_dict[key][selected_columns]\n",
    "\n",
    "    y_train_dict[key] = train_dict[key].is_duplicate\n",
    "    y_test_dict[key] = test_dict[key].is_duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Apprentissage et performance\n",
    "\n",
    "Pour tester les perfomances des modeles nous allons entrainer une regression logistic, un random forest et un arbre de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_dict = {}\n",
    "lr_time = {}\n",
    "\n",
    "for key in train_dict:\n",
    "    st = time.time()\n",
    "    lr_dict[key] = LogisticRegression() \n",
    "    lr_dict[key].fit(x_train_dict[key], y_train_dict[key])\n",
    "    lr_time[key] = time.time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{400000: 0.33588671684265137,\n",
       " 1000: 0.0021741390228271484,\n",
       " 10000: 0.006098031997680664,\n",
       " 100000: 0.06316709518432617,\n",
       " 800000: 0.61788010597229,\n",
       " 1200000: 0.9612510204315186}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full 0.6707643853009804\n",
      "1000 0.7133333333333334\n",
      "10000 0.6756666666666666\n",
      "100000 0.6802333333333334\n"
     ]
    }
   ],
   "source": [
    "for key in train_dict:\n",
    "    y_pred = lr_dict[key].predict(x_test_dict[key])\n",
    "    print(key, accuracy_score(y_pred, y_test_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "\n",
    "dt_dict = {}\n",
    "\n",
    "dt_time = {}\n",
    "\n",
    "for key in train_dict:\n",
    "    st = time.time()\n",
    "    dt_dict[key] = tree.DecisionTreeClassifier()\n",
    "    dt_dict[key].fit(x_train_dict[key], y_train_dict[key])\n",
    "    dt_time[key] = time.time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{400000: 1.048037052154541,\n",
       " 1000: 0.0037539005279541016,\n",
       " 10000: 0.016834020614624023,\n",
       " 100000: 0.19215893745422363,\n",
       " 800000: 2.2114639282226562,\n",
       " 1200000: 3.7533140182495117}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full 0.7066627091114464\n",
      "1000 0.6733333333333333\n",
      "10000 0.688\n",
      "100000 0.7007666666666666\n"
     ]
    }
   ],
   "source": [
    "for key in train_dict:\n",
    "    y_pred = dt_dict[key].predict(x_test_dict[key])\n",
    "    print(key, accuracy_score(y_pred, y_test_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/mnannan/.virtualenvs/supelec/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_dict = {}\n",
    "\n",
    "rf_time = {}\n",
    "\n",
    "for key in train_dict:\n",
    "    st = time.time()\n",
    "    rf_dict[key] = RandomForestClassifier()\n",
    "    rf_dict[key].fit(x_train_dict[key], y_train_dict[key])\n",
    "    rf_time[key] = time.time() - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{400000: 5.257158279418945,\n",
       " 1000: 0.012971639633178711,\n",
       " 10000: 0.06613922119140625,\n",
       " 100000: 0.8663570880889893,\n",
       " 800000: 14.837876796722412,\n",
       " 1200000: 25.868048191070557}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full 0.7080313636251205\n",
      "1000 0.6966666666666667\n",
      "10000 0.6876666666666666\n",
      "100000 0.7030333333333333\n"
     ]
    }
   ],
   "source": [
    "for key in train_dict:\n",
    "    y_pred = rf_dict[key].predict(x_test_dict[key])\n",
    "    print(key, accuracy_score(y_pred, y_test_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supelec",
   "language": "python",
   "name": "supelec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
